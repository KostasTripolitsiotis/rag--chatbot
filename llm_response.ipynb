{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75117c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "from ipynb.fs.full.retriever import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789b1833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query):\n",
    "    \"\"\"\n",
    "    This function takes a query string, retrieves relevant chunks of text from a database,\n",
    "    and then uses the Ollama API to generate a response based on those chunks.\n",
    "    \"\"\"\n",
    "    # Retrieve relevant chunks of text\n",
    "    res = \"\\n\".join(ask(query))\n",
    "    \n",
    "    # Prepare the question for the model\n",
    "    question = \"From the following chunks of text, answer this question: \" + query + \"\\n\\n\" + res\n",
    "    \n",
    "    # Generate a response using the Ollama API\n",
    "    response = ollama.chat(\n",
    "        model=\"deepseek-r1:7b\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": question}\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Modify the response format\n",
    "    response = response[\"message\"][\"content\"]\n",
    "    response = response.split(\"</think>\")\n",
    "    response[0] = response[0].replace(\"<think>\", \"``\")\n",
    "    response[0] += \"``\"\n",
    "    \n",
    "    # Return the generated response\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdd080d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = \"<think> Okay, so I need to figure out how Baker Hughes engineers used MATLAB to develop pump health monitoring software based on the given chunks of text. Let me start by reading through each chunk carefully and noting down key points. Chunk 1 talks about the need for predicting when a pump is about to fail to optimize maintenance without wasting resources. The engineers developed software using machine learning in real-time, processing up to a terabyte of data. That's a lot! Chunk 2 mentions a truck with positive displacement pumps used in gas and oil extraction. It also refers to predictive maintenance software but doesn't go into much detail. Chunk 3 is an example from Mondi where their software runs continuously, which I assume relates to the need for real-time monitoring. Chunk 4 discusses Gulshan Singh's experience using MATLAB's built-in capabilities saving time compared to lower-level languages. So this supports the use of MATLAB for efficient development. Chunk 5 provides more specifics: processing data at 50k samples per second from sensors on multiple trucks, identifying useful parameters, creating and training a neural network, leading to cost savings over $10 million. Putting it all together, it seems the engineers used MATLAB's tools for handling large datasets, implementing machine learning models (like neural networks), and deploying them in real-time systems. They also emphasized efficiency through MATLAB's high-level functions instead of lower-level code. </think> Baker Hughes utilized MATLAB to develop pump health monitoring software by leveraging its powerful data processing capabilities and machine learning tools. The engineers collected massive datasets from sensors installed on their trucks, analyzing up to 50,000 samples per second across multiple units. Using these data points, they identified critical parameters indicative of impending pump failures and trained a neural network to predict such events in real time. This approach allowed for precise timing of maintenance, preventing unnecessary replacements and optimizing resource allocation. MATLAB's high-level functions significantly accelerated the development process compared to lower-level languages, ensuring efficient implementation. The resulting software is designed to run continuously in production environments, enhancing reliability and cost-effectiveness by reducing maintenance expenses by over 30%.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452eb2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"`` Okay, so I need to figure out how Baker Hughes engineers used MATLAB to develop pump health monitoring software based on the given chunks of text. Let me start by reading through each chunk carefully and noting down key points. Chunk 1 talks about the need for predicting when a pump is about to fail to optimize maintenance without wasting resources. The engineers developed software using machine learning in real-time, processing up to a terabyte of data. That's a lot! Chunk 2 mentions a truck with positive displacement pumps used in gas and oil extraction. It also refers to predictive maintenance software but doesn't go into much detail. Chunk 3 is an example from Mondi where their software runs continuously, which I assume relates to the need for real-time monitoring. Chunk 4 discusses Gulshan Singh's experience using MATLAB's built-in capabilities saving time compared to lower-level languages. So this supports the use of MATLAB for efficient development. Chunk 5 provides more specifics: processing data at 50k samples per second from sensors on multiple trucks, identifying useful parameters, creating and training a neural network, leading to cost savings over $10 million. Putting it all together, it seems the engineers used MATLAB's tools for handling large datasets, implementing machine learning models (like neural networks), and deploying them in real-time systems. They also emphasized efficiency through MATLAB's high-level functions instead of lower-level code. ``\",\n",
       " \" Baker Hughes utilized MATLAB to develop pump health monitoring software by leveraging its powerful data processing capabilities and machine learning tools. The engineers collected massive datasets from sensors installed on their trucks, analyzing up to 50,000 samples per second across multiple units. Using these data points, they identified critical parameters indicative of impending pump failures and trained a neural network to predict such events in real time. This approach allowed for precise timing of maintenance, preventing unnecessary replacements and optimizing resource allocation. MATLAB's high-level functions significantly accelerated the development process compared to lower-level languages, ensuring efficient implementation. The resulting software is designed to run continuously in production environments, enhancing reliability and cost-effectiveness by reducing maintenance expenses by over 30%.\"]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# response = response.split(\"</think>\")\n",
    "# response[0] = response[0].replace(\"<think>\", \"``\")\n",
    "# response[0] += \"``\"\n",
    "# response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de664331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
